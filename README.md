

## How the Data Was Scraped

The data was scraped using the GitHub API. The `users.csv` file contains user details such as login, name, company, location, email, hireable status, bio, public repositories, followers, following count, and the date they joined GitHub. A script was used to filter users based in Boston with over 100 followers and format their information accordingly.


## Files Included

- `users.csv`: Contains details about GitHub users in Boston with over 100 followers.
- `repositories.csv`: Lists public repositories owned by the users in `users.csv`.
- `README.md`: This file documenting the project and its findings.

